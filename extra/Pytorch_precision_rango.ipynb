{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dd395ca",
   "metadata": {},
   "source": [
    "# PyTorch: Rango dinámico, precisión y tiempos (FP16, FP32, FP64, bfloat16)\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En esta notebook exploraremos los diferentes tipos de datos numéricos que PyTorch utiliza para representar tensores. Comprenderemos las diferencias fundamentales entre precisión y rango dinámico, y cómo estas diferencias afectan el rendimiento computacional.\n",
    "\n",
    "**Objetivos:**\n",
    "- Entender la diferencia entre rango dinámico y precisión\n",
    "- Comparar los tipos de datos más comunes: FP16, FP32, FP64 y bfloat16\n",
    "- Medir el impacto en memoria y velocidad de cada tipo\n",
    "- Identificar cuándo usar cada tipo de dato en la práctica"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f17a13",
   "metadata": {},
   "source": [
    "## Fundamentos teóricos: Representación de números en coma flotante\n",
    "\n",
    "Un número en coma flotante se representa matemáticamente como:\n",
    "\n",
    "$$x = (-1)^{signo} \\times 1.mantisa \\times 2^{exponente}$$\n",
    "\n",
    "Donde cada componente cumple una función específica:\n",
    "\n",
    "- **Exponente → rango dinámico**: Determina qué tan grandes o pequeños pueden ser los números sin causar overflow/underflow\n",
    "- **Mantisa → precisión**: Controla cuántos dígitos significativos se conservan en la representación\n",
    "\n",
    "### Distribución de bits por tipo\n",
    "\n",
    "Los diferentes tipos de datos asignan bits de manera distinta:\n",
    "\n",
    "- **FP16**: 1 signo + 5 exponente + 10 mantisa → rango limitado, precisión moderada\n",
    "- **FP32**: 1 signo + 8 exponente + 23 mantisa → buen equilibrio entre rango y precisión\n",
    "- **FP64**: 1 signo + 11 exponente + 52 mantisa → máximo rango y precisión\n",
    "- **bfloat16**: 1 signo + 8 exponente + 7 mantisa → mismo rango que FP32, menor precisión\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a6f4cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66f0f3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = \"cpu\"  # por defecto, usamos la CPU\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = \"cuda\"  # si hay GPU, usamos la GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = \"mps\"  # si no hay GPU, pero hay MPS, usamos MPS\n",
    "elif torch.backends.xpu.is_available():\n",
    "    DEVICE = \"xpu\"  # si no hay GPU, pero hay XPU, usamos XPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67304c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_dic = {\n",
    "    \"float16\": torch.float16,\n",
    "    \"float32\": torch.float32,\n",
    "    \"float64\": torch.float64,\n",
    "    \"bfloat16\": torch.bfloat16\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce45cb3",
   "metadata": {},
   "source": [
    "Cada tipo de dato tiene limitaciones específicas que determinan su aplicabilidad:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52d9c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16    | bits=16 | eps=9.77e-04 | min=-6.55e+04 | max=6.55e+04\n",
      "float32    | bits=32 | eps=1.19e-07 | min=-3.40e+38 | max=3.40e+38\n",
      "float64    | bits=64 | eps=2.22e-16 | min=-1.80e+308 | max=1.80e+308\n",
      "bfloat16   | bits=16 | eps=7.81e-03 | min=-3.39e+38 | max=3.39e+38\n"
     ]
    }
   ],
   "source": [
    "def show_finfo(dtype, name):\n",
    "    try:\n",
    "        info = torch.finfo(dtype)\n",
    "        print(f\"{name:<10} | bits={info.bits} | eps={info.eps:.2e} | min={info.min:.2e} | max={info.max:.2e}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{name:<10} | no disponible -> {e}\")\n",
    "\n",
    "for name, dtype in dtype_dic.items():\n",
    "    show_finfo(dtype, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58a89bb",
   "metadata": {},
   "source": [
    "**Interpretación de resultados:**\n",
    "\n",
    "- **bits**: Cantidad total de bits utilizados para la representación.\n",
    "- **eps**: Representa la precisión máxima del tipo. Es el menor número positivo tal que $1.0 + \\text{eps} \\neq 1.0$\n",
    "- **min/max**: Indican el rango dinámico, es decir, los valores extremos que se pueden representar sin overflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988653b1",
   "metadata": {},
   "source": [
    "### Demostración de pérdida de precisión\n",
    "\n",
    "El problema clásico de la aritmética de punto flotante:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "098ca0e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float16: 0.1 + 0.2 = 0.2998046875 | error = 1.95e-04\n",
      "float32: 0.1 + 0.2 = 0.3000000119 | error = 1.19e-08\n",
      "float64: 0.1 + 0.2 = 0.3000000000 | error = 5.55e-17\n",
      "bfloat16: 0.1 + 0.2 = 0.3007812500 | error = 7.81e-04\n"
     ]
    }
   ],
   "source": [
    "# Problema clásico: 0.1 + 0.2 ≠ 0.3\n",
    "for name, dtype in dtype_dic.items():\n",
    "    a = torch.tensor(0.1, dtype=dtype)\n",
    "    b = torch.tensor(0.2, dtype=dtype)\n",
    "    resultado = a + b\n",
    "    error = abs(resultado.item() - 0.3)\n",
    "    print(f\"{name}: 0.1 + 0.2 = {resultado:.10f} | error = {error:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870ee4a6",
   "metadata": {},
   "source": [
    "Este experimento ilustra cómo la precisión limitada de cada tipo afecta operaciones aparentemente simples. La diferencia con el resultado esperado (0.3) varía según el tipo de dato utilizado."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5105e6",
   "metadata": {},
   "source": [
    "### Overflow: Desbordamiento numérico\n",
    "\n",
    "Cuando un cálculo produce un resultado que excede el rango máximo del tipo de dato:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "db346f2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "float16:\n",
      "  max = 65504.0\n",
      "  max + 10 = 65504.0\n",
      "  max * 2 = inf\n",
      "\n",
      "float32:\n",
      "  max = 3.4028234663852886e+38\n",
      "  max + 10 = 3.4028234663852886e+38\n",
      "  max * 2 = inf\n",
      "\n",
      "float64:\n",
      "  max = 1.7976931348623157e+308\n",
      "  max + 10 = 1.7976931348623157e+308\n",
      "  max * 2 = inf\n",
      "\n",
      "bfloat16:\n",
      "  max = 3.3895313892515355e+38\n",
      "  max + 10 = 3.3895313892515355e+38\n",
      "  max * 2 = inf\n"
     ]
    }
   ],
   "source": [
    "# Overflow: cuando el número es demasiado grande\n",
    "for name, dtype in dtype_dic.items():\n",
    "    info = torch.finfo(dtype)\n",
    "    x = torch.tensor(info.max, dtype=dtype)\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  max = {x}\")\n",
    "    print(f\"  max + 10 = {x + 10}\")\n",
    "    print(f\"  max * 2 = {x * 2}\")  # ¡Overflow!\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44658ec0",
   "metadata": {},
   "source": [
    "> También existe el underflow: cuando un cálculo produce un resultado que está por debajo del rango mínimo del tipo de dato."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8052cd9d",
   "metadata": {},
   "source": [
    "## Análisis de rendimiento computacional\n",
    "\n",
    "### Configuración del experimento\n",
    "\n",
    "Para evaluar el impacto real de cada tipo de dato, realizaremos multiplicaciones de matrices de gran escala. Este tipo de operación es fundamental en deep learning y permite observar diferencias significativas de rendimiento.\n",
    "\n",
    "A tener en cuenta: \n",
    "- **Warm-up**: Las primeras ejecuciones incluyen tiempo de inicialización de kernels GPU y asignación de memoria. El warm-up elimina estos efectos transitorios.\n",
    "- **Synchronization**: Las GPU ejecutan operaciones de forma asíncrona. `torch.cuda.synchronize()` garantiza que medimos el tiempo real de cómputo, no solo el tiempo de envío de la operación.\n",
    "- **Múltiples ejecuciones**: El comando `%timeit` ejecuta la operación múltiples veces y calcula estadísticas, proporcionando mediciones más robustas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbe517d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando: cuda\n",
      "\n",
      "Tamaño de matrices: 2048x2048\n",
      "\n",
      "float16 (torch.float16):\n",
      "  Memoria: 16.0 MB\n",
      "float16:\n",
      "381 μs ± 32.1 μs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "\n",
      "float32 (torch.float32):\n",
      "  Memoria: 32.0 MB\n",
      "float32:\n",
      "995 μs ± 29.6 μs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "\n",
      "float64 (torch.float64):\n",
      "  Memoria: 64.0 MB\n",
      "float64:\n",
      "41.8 ms ± 173 μs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "\n",
      "bfloat16 (torch.bfloat16):\n",
      "  Memoria: 16.0 MB\n",
      "bfloat16:\n",
      "354 μs ± 23.4 μs per loop (mean ± std. dev. of 5 runs, 10 loops each)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "size = 2048\n",
    "\n",
    "print(f\"Usando: {DEVICE}\\n\")\n",
    "print(f\"Tamaño de matrices: {size}x{size}\\n\")\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, dtype in dtype_dic.items():\n",
    "    try:\n",
    "        print(f\"{name} ({dtype}):\")\n",
    "        \n",
    "        # Crear matrices\n",
    "        A = torch.randn(size, size, dtype=dtype, device=DEVICE)\n",
    "        B = torch.randn(size, size, dtype=dtype, device=DEVICE)\n",
    "        \n",
    "        # Mostrar uso de memoria\n",
    "        memory_mb = (A.element_size() + B.element_size()) * size * size / (1024**2)\n",
    "        print(f\"  Memoria: {memory_mb:.1f} MB\")\n",
    "        \n",
    "        # Warm-up: necesario para estabilizar medidas\n",
    "        for _ in range(10):\n",
    "            _ = torch.mm(A, B)\n",
    "        torch.cuda.synchronize() # Esperar a que GPU termine\n",
    "        \n",
    "        print(f\"{name}:\")\n",
    "        %timeit -n 10 -r 5 torch.mm(A, B); torch.cuda.synchronize()\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  {name:<10} | no disponible -> {e}\")\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c987752",
   "metadata": {},
   "source": [
    "## Consideraciones para la práctica\n",
    "\n",
    "### Cuándo usar cada tipo\n",
    "\n",
    "**FP32**: Punto de partida recomendado\n",
    "- Desarrollo y prototipado\n",
    "- Cuando la precisión es crítica\n",
    "- Modelos que caben en memoria disponible\n",
    "\n",
    "**FP16/bfloat16**: Optimización de producción\n",
    "- Modelos grandes que requieren eficiencia\n",
    "- Hardware con soporte para Tensor Cores\n",
    "- Entrenamiento distribuido\n",
    "\n",
    "**FP64**: Casos especializados\n",
    "- Computación científica de alta precisión\n",
    "- Simulaciones numéricas críticas\n",
    "- Validación de algoritmos\n",
    "\n",
    "### Limitaciones y precauciones\n",
    "\n",
    "- **Underflow numérico**: FP16 es más susceptible a gradientes muy pequeños\n",
    "- **Compatibilidad de hardware**: No todos los dispositivos soportan todos los tipos eficientemente\n",
    "- **Estabilidad numérica**: Algoritmos pueden requerir ajustes para tipos de menor precisión"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
